import json
import re

from ..hooks.llm_hook import run_llm_structured
from ..hooks.supabase_hook import get_contexts, get_individual_memory
from ..hooks.embedding_hook import get_embedding, cosine_similarity


def should_save_embedding(
    new_context: str, scope: str, user: str, threshold: float = 0.85
):

    new_embedding = get_embedding(new_context)

    if scope == "personal":
        individual_memorys = get_individual_memory(user)
        if not individual_memorys.data:
            print("üì¶ Mem√≥ria individual vazia ‚Äî salvando direto")
            return True

        for memory in individual_memorys.data:
            stored_embedding = memory.get("embedding")

            if not stored_embedding:
                print("‚ö†Ô∏è Mem√≥ria individual sem embedding ‚Äî ignorando")
                continue

            if isinstance(stored_embedding, str):
                try:
                    stored_embedding = json.loads(stored_embedding)
                except Exception as e:
                    print("‚ö†Ô∏è Erro ao converter embedding individual:", e)
                    continue

            if not isinstance(stored_embedding, list):
                print("‚ö†Ô∏è Embedding individual inv√°lido ‚Äî ignorando")
                continue

            similarity = cosine_similarity(new_embedding, stored_embedding)
            print(f"üîÅ Similaridade (individual) detectada: {similarity:.4f}")

            if similarity >= threshold:
                print("üö´ Mem√≥ria individual duplicada ‚Äî N√ÉO SALVAR")
                return False

        print("‚úÖ Mem√≥ria individual nova ‚Äî PODE SALVAR")
        return True

    else:
        existing = get_contexts()

        if not existing:
            print("üì¶ Banco vazio ‚Äî salvando direto")
            return True

        for memory in existing:
            stored_embedding = memory.get("embedding")

            if not stored_embedding:
                print("‚ö†Ô∏è Registro sem embedding ‚Äî ignorando")
                continue

            if isinstance(stored_embedding, str):
                try:
                    stored_embedding = json.loads(stored_embedding)
                except Exception as e:
                    print("‚ö†Ô∏è Erro ao converter embedding:", e)
                    continue

            if not isinstance(stored_embedding, list):
                print("‚ö†Ô∏è Embedding inv√°lido ‚Äî ignorando")
                continue

            similarity = cosine_similarity(new_embedding, stored_embedding)

            print(f"üîÅ Similaridade detectada: {similarity:.4f}")

            if similarity >= threshold:
                print("üö´ Mem√≥ria duplicada detectada ‚Äî N√ÉO VAI SALVAR")
                return False

        print("‚úÖ Mem√≥ria nova ‚Äî PODE SALVAR")
        return True


def classify_global_memory(message: str, user):
    """
    Classifica se a mensagem deve gerar mem√≥ria global.
    Depois valida se essa mem√≥ria j√° existe usando embedding.
    """

    prompt = f"""
Voc√™ √© um classificador EXTREMAMENTE RIGOROSO de MEM√ìRIA da IA.

Sua fun√ß√£o √© identificar:
1) Se a mensagem deve virar mem√≥ria
2) Se ela √© mem√≥ria COLETIVA (global) ou INDIVIDUAL (personal)

DEFINI√á√ïES IMPORTANTES:

üü® MEM√ìRIA INDIVIDUAL (scope = "personal")
Deve ser salva quando a informa√ß√£o for:
- uma prefer√™ncia pessoal do usu√°rio
- um estilo que s√≥ ele quer usar
- uma forma espec√≠fica como ele quer receber suas copys
- rotinas ou padr√µes privados
- salvar quando houver pronome pr√≥prio EXPL√çCITO, JUNTAMENTE com uma PREFER√äNCIA (minha, eu gosto, eu prefiro‚Ä¶)
- ajustes que N√ÉO devem afetar outros usu√°rios

üü¶ MEM√ìRIA COLETIVA (scope = "global")
Deve ser salva apenas quando a instru√ß√£o for:
- uma regra permanente da MARCA BOMMA
- um padr√£o de escrita oficial
- um posicionamento fixo da marca
- uma diretriz estrutural do sistema
- um processo universal aplicado para TODOS os usu√°rios

‚ö†Ô∏è NUNCA salvar:
- Briefings espec√≠ficos
- Informa√ß√µes de um √∫nico projeto
- Ajustes tempor√°rios
- Respostas de refinamento
- Tarefas √∫nicas
- Pedidos de execu√ß√£o

Exemplos de mem√≥ria INDIVIDUAL:
- ‚Äúminhas copys devem sempre come√ßar com X‚Äù
- ‚Äúprefiro textos mais diretos‚Äù
- ‚Äúsempre deixe minhas legendas curtas‚Äù

IMPORTANTE para mem√≥rias INDIVIDUAIS:
- as mem√≥rias individuais tem APENAS o "content", ou seja, ele tem que ser autoexplicativo, sem depender da tag ou context.

Exemplos de mem√≥ria COLETIVA:
- ‚Äúa BOMMA nunca usa emoji‚Äù
- ‚Äúa comunica√ß√£o da marca evita termos de venda agressiva‚Äù
- ‚Äúo posicionamento da BOMMA √© maduro e t√©cnico‚Äù

Responda SEMPRE com JSON v√°lido:

{{
  "should_save": true ou false,
  "scope": "global" ou "personal",
  "content": "o que deve ser salvo",
  "context": "quando aplicar",
  "tag": "regra | estilo | script | fato | processo | misc"
}}

Mensagem do usu√°rio:
\"{message}\"
"""

    # ‚úÖ Classifica√ß√£o inicial via LLM
    # print("PROMPT CLASSIFY MEMORY: ", prompt)
    memory = run_llm_structured(prompt)

    # ‚úÖ Prote√ß√£o contra erro de JSON da LLM
    if not isinstance(memory, dict):
        return {
            "should_save": False,
            "scope": "none",
            "content": "",
            "context": "",
            "tag": "misc",
        }

    if not memory.get("context"):
        memory["should_save"] = False
        memory["scope"] = "none"
        return memory

    if memory.get("should_save") is False:
        return memory

    is_new = should_save_embedding(
        memory["context"] + " " + memory["content"], memory["scope"], user
    )

    memory["should_save"] = is_new

    return memory
