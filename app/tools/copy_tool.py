from app.hooks.llm_hook import run_llm
from app.classifiers.public_classifier import classify_public, get_public_prompt
from app.classifiers.format_classifier import classify_format, get_format_prompt
from app.classifiers.context_classifier import classify_context, get_context_prompt

# from app.classifiers.copy_readiness_classifier import (
#     build_missing_questions,
#     classify_copy_readiness,
# )

from typing import Any, Dict, List, Optional, Union
import json


def _normalize_contexts(
    raw_contexts: Union[str, Dict[str, Any], List[Dict[str, Any]], None],
) -> List[Dict[str, Any]]:
    if raw_contexts is None:
        return []

    # Se j√° veio lista de dicts
    if isinstance(raw_contexts, list):
        return [c for c in raw_contexts if isinstance(c, dict)]

    # Se veio um √∫nico dict
    if isinstance(raw_contexts, dict):
        return [raw_contexts]

    # Se veio string (possivelmente JSON)
    if isinstance(raw_contexts, str):
        raw = raw_contexts.strip()
        if not raw:
            return []
        try:
            parsed = json.loads(raw)
            if isinstance(parsed, list):
                return [c for c in parsed if isinstance(c, dict)]
            if isinstance(parsed, dict):
                return [parsed]
        except Exception:
            # Se n√£o for JSON v√°lido, ignora silenciosamente
            return []

    return []


def _build_contexts_prompt(contexts: List[Dict[str, Any]]) -> str:
    """
    Constr√≥i o bloco de prompt com as mem√≥rias/contextos ativos.
    """
    if not contexts:
        return ""

    lines = []
    for c in contexts:
        tag = (c.get("tag") or "").strip()
        content = (c.get("content") or c.get("context") or "").strip()

        if not content:
            continue

        if tag:
            lines.append(f"- ({tag}) {content}")
        else:
            lines.append(f"- {content}")

    if not lines:
        return ""

    return (
        "üéØ CONTEXTOS / REGRAS ATIVAS (OBRIGAT√ìRIO CONSIDERAR NA RESPOSTA):\n"
        + "\n".join(lines)
    )


def _extract_requested_quantity(message: str) -> Optional[int]:
    """
    Tenta identificar se o usu√°rio pediu explicitamente N copys / legendas.
    Ex: "preciso de 3 copies", "fa√ßa 2 legendas", etc.
    S√≥ considera n√∫meros expl√≠citos (d√≠gitos).
    """
    import re

    msg = message.lower()
    pattern = r"(\d+)\s*(copy|copys|c√≥pias|copias|legenda|legendas|textos|copies)"
    match = re.search(pattern, msg)
    if not match:
        return None

    try:
        n = int(match.group(1))
        if 1 <= n <= 10:
            return n
    except Exception:
        return None

    return None


def generate_bomma_copy_debug(
    input_text: str,
    conversation: str,
    contexts: Any,
    user_name: Optional[str] = None,
    **kwargs: Any,
) -> Dict[str, Any]:
    """
    Tool oficial de gera√ß√£o de copy da BOMMA.

    - Usa classificadores de p√∫blico, formato e contexto.
    - Injeta mem√≥rias/contextos relevantes.
    - Aplica diretrizes oficiais da BOMMA.
    - Gera copy final pronta para uso.
    """

    # ==============================
    # 1) Log b√°sico para debug
    # ==============================
    print("\n[COPY_TOOL] Tool acionada!")
    print(f"[COPY_TOOL] user_id: {user_name}")
    print(f"[COPY_TOOL] input_text: {input_text}")
    print(f"[COPY_TOOL] conversation: {conversation}")
    print(f"[COPY_TOOL] contexts (raw): {contexts}")
    print(f"[COPY_TOOL] extra_kwargs: {kwargs}\n")

    # ==============================
    # 2) Normalizar contextos/mem√≥rias
    # ==============================
    active_contexts = _normalize_contexts(contexts)
    contexts_prompt = _build_contexts_prompt(active_contexts)

    # ==============================
    # 3) Classifica√ß√µes principais
    # ==============================
    try:
        publico = classify_public(input_text) or "nenhum"
    except Exception as e:
        print(f"[COPY_TOOL] ERRO classify_public: {e}")
        publico = "nenhum"

    try:
        formato = classify_format(input_text) or "generico"
    except Exception as e:
        print(f"[COPY_TOOL] ERRO classify_format: {e}")
        formato = "generico"

    try:
        contexto = classify_context(input_text) or "none"
    except Exception as e:
        print(f"[COPY_TOOL] ERRO classify_context: {e}")
        contexto = "none"

    print(f"[COPY_TOOL] p√∫blico classificado: {publico}")
    print(f"[COPY_TOOL] formato classificado: {formato}")
    print(f"[COPY_TOOL] contexto classificado: {contexto}")

    # ==============================
    # 4) Blocos de prompt espec√≠ficos
    # ==============================
    public_block = ""
    format_block = ""
    context_block = ""

    try:
        public_block = get_public_prompt(publico)
    except Exception as e:
        print(f"[COPY_TOOL] ERRO get_public_prompt: {e}")

    try:
        format_block = get_format_prompt(formato)
    except Exception as e:
        print(f"[COPY_TOOL] ERRO get_format_prompt: {e}")

    try:
        context_block = get_context_prompt(contexto)
    except Exception as e:
        print(f"[COPY_TOOL] ERRO get_context_prompt: {e}")

    # ==============================
    # 5) Quantidade de varia√ß√µes (se houver)
    # ==============================
    requested_qty = _extract_requested_quantity(input_text)
    qty_instruction = ""
    if requested_qty is not None:
        qty_instruction = (
            f"\nINSTRU√á√ÉO DE QUANTIDADE:\n"
            f"- O usu√°rio pediu explicitamente {requested_qty} varia√ß√£o(√µes).\n"
            f"- Produza EXATAMENTE {requested_qty} copies, numeradas como:\n"
            f"  1) ...\n"
            f"  2) ...\n"
            f"  (e assim por diante).\n"
        )

    # ==============================
    # 6) Prompt-mestre BOMMA
    # ==============================
    system_core = f"""
Voc√™ √© a IA copywriter oficial da BOMMA, especializada em arquitetura, interiores
e mercado imobili√°rio, com foco em textos que respeitam rigorosamente as diretrizes
da marca.

HIERARQUIA DE PRIORIDADE (SIGA SEMPRE NA ORDEM, SEM EXCE√á√ïES):

1. REGRAS DA MARCA (N√çVEL M√ÅXIMO)
   - Nada pode violar as diretrizes oficiais da BOMMA.
   - Isso inclui tom, restri√ß√µes de palavras, postura, fun√ß√£o da copy e foco no arquiteto.

2. CONTEXTOS COLETIVOS ATIVOS (N√çVEL ALTO)
   - S√£o instru√ß√µes v√°lidas para todos os usu√°rios.
   - Podem complementar ou detalhar as regras da marca, mas n√£o podem contrari√°-las.

3. MEM√ìRIAS INDIVIDUAIS DO USU√ÅRIO
   - S√£o prefer√™ncias pessoais de tom, estrutura ou estilo.
   - Devem ser respeitadas sempre que N√ÉO entrarem em conflito com os n√≠veis 1 e 2.

4. PEDIDO ATUAL DO USU√ÅRIO
   - O pedido √© atendido completamente, desde que n√£o viole nenhum n√≠vel acima.

EM CASO DE CONFLITO:
- O n√≠vel mais alto sempre prevalece.
- Nunca tente conciliar se isso violaria os n√≠veis superiores.

OBJETIVO:
- Transformar o pedido do usu√°rio em uma copy final pronta para uso, SEM explicar o processo.
- Sempre priorizar clareza, maturidade e alinhamento com o posicionamento da BOMMA.

REGRA FUNDAMENTAL DE POSICIONAMENTO:
- Voc√™ NUNCA deve escrever uma copy vendendo o im√≥vel em si.
- Toda copy deve obrigatoriamente comunicar o projeto do arquiteto aplicado ao im√≥vel.
- O im√≥vel √© apenas o suporte f√≠sico. O produto real √© a solu√ß√£o arquitet√¥nica.
- Sempre destaque decis√£o de projeto, inten√ß√£o, funcionalidade, experi√™ncia e est√©tica criadas pelo arquiteto.

RESTRI√á√ïES GERAIS (SEM EXCE√á√ÉO):
- N√ÉO usar palavras como: "luxo", "sonho", "sonhos", "premium", "alto padr√£o", "exclusivo",
  "oportunidade imperd√≠vel", "venha conhecer", "agende uma visita", "condom√≠nio clube",
  "localiza√ß√£o privilegiada" ou qualquer clich√™ t√≠pico de an√∫ncio imobili√°rio.
- N√ÉO usar tom de venda agressivo.
- N√ÉO escrever em caixa alta (NADA de frases inteiras em mai√∫sculas).
- N√ÉO usar emojis.
- N√ÉO explicar o que voc√™ est√° fazendo.
- N√ÉO repetir a mensagem do usu√°rio.

FORMATO DA RESPOSTA:
- Entregue apenas a(s) copy(s), sem coment√°rios, sem t√≠tulos, sem markdown.
- Se houver mais de uma varia√ß√£o, numere assim: "1) ...", "2) ...".
- N√£o escreva nada fora do texto que o usu√°rio possa publicar.

REGRA DE CTA (OBRIGAT√ìRIA):
- Toda copy deve conter UM CTA no final, adequado ao formato:
  - Para ADS ‚Üí CTA leve de a√ß√£o (ex: conversar, saber mais, entrar em contato)
  - Para LEGENDA ‚Üí CTA elegante e discreto
  - Para GENERICO ‚Üí CTA suave e natural
- O CTA nunca deve ser agressivo.
- Nunca usar chamadas como:
  "compre agora", "√∫ltimas unidades", "imperd√≠vel", "corra", "promo√ß√£o".

METADADOS CLASSIFICADOS (USE APENAS COMO GUIA INTERNO, N√ÉO MOSTRAR):
- P√∫blico-alvo: {publico}
- Formato: {formato}
- Contexto do im√≥vel: {contexto}

QUALQUER viola√ß√£o de regra acima invalida completamente a resposta.
Se qualquer termo proibido for usado, a resposta deve ser considerada incorreta.
"""

    # Monta bloco de m√≥dulos
    modules_block_parts = []

    if public_block.strip():
        modules_block_parts.append("=== M√ìDULO DE P√öBLICO ===\n" + public_block.strip())

    if format_block.strip():
        modules_block_parts.append("=== M√ìDULO DE FORMATO ===\n" + format_block.strip())

    if context_block.strip():
        modules_block_parts.append(
            "=== M√ìDULO DE CONTEXTO ===\n" + context_block.strip()
        )

    modules_block = "\n\n".join(modules_block_parts)

    # Bloco de contextos/mem√≥rias
    if contexts_prompt:
        contexts_block = (
            "\n=== M√ìDULO DE MEM√ìRIA / CONTEXTO VIVO ===\n" + contexts_prompt
        )
    else:
        contexts_block = ""

    # Conversa recente (somente para dar contexto de di√°logo)
    conversation_block = ""
    if conversation:
        conversation_block = f"""
=== HIST√ìRICO RESUMIDO DA CONVERSA ===
Use apenas como refer√™ncia contextual, mas responda ao pedido final do usu√°rio.
{conversation.strip()}
"""

    final_prompt = f"""
    {system_core}
    
    {qty_instruction}
    
    {modules_block}
    
    {contexts_block}
    
    {conversation_block}
    
    === PEDIDO FINAL DO USU√ÅRIO ===
    {input_text}
    
    AGORA, GERE APENAS A COPY FINAL, J√Å PRONTA PARA USO, RESPEITANDO TODAS AS REGRAS ACIMA.
    """
    # print("final prompt: ", final_prompt)

    try:
        raw_response = run_llm(
            final_prompt,
            model="gpt-5.1",
            temperature=0.7,
        )
        copy_text = (raw_response or "").strip()
        if not copy_text:
            copy_text = (
                "N√£o foi poss√≠vel gerar a copy neste momento. "
                "Tente reformular o pedido ou tentar novamente em instantes."
            )
    except Exception as e:
        print(f"[COPY_TOOL] ERRO ao chamar LLM: {e}")
        copy_text = (
            "Ocorreu um erro interno ao gerar a copy. "
            "Tente novamente em alguns instantes."
        )

    # ==============================
    # 8) Retorno estruturado
    # ==============================
    return {
        "copy": copy_text,
        "metadata": {
            "user_id": user_name,
            "publico": publico,
            "formato": formato,
            "contexto": contexto,
            "requested_quantity": requested_qty,
            "active_contexts": active_contexts,
            "model_used": "gpt-4o",
            "debug": False,
        },
    }
