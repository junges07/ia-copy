from typing import Any, Dict, List, Optional, Union
import json

from app.hooks.llm_hook import run_llm
from app.classifiers.public_classifier import classify_public, get_public_prompt
from app.classifiers.format_classifier import classify_format, get_format_prompt
from app.classifiers.context_classifier import classify_context, get_context_prompt


def _normalize_contexts(
    raw_contexts: Union[str, Dict[str, Any], List[Dict[str, Any]], None],
) -> List[Dict[str, Any]]:
    """
    Normaliza mem√≥rias/contextos ativos para uma lista de dicts.
    Aceita: None | dict | list[dict] | str(JSON de dict/list).
    """
    if raw_contexts is None:
        return []

    if isinstance(raw_contexts, list):
        return [c for c in raw_contexts if isinstance(c, dict)]

    if isinstance(raw_contexts, dict):
        return [raw_contexts]

    if isinstance(raw_contexts, str):
        raw = raw_contexts.strip()
        if not raw:
            return []
        try:
            parsed = json.loads(raw)
            if isinstance(parsed, list):
                return [c for c in parsed if isinstance(c, dict)]
            if isinstance(parsed, dict):
                return [parsed]
        except Exception:
            return []

    return []


def _build_contexts_prompt(contexts: List[Dict[str, Any]]) -> str:
    """
    Constr√≥i o bloco de prompt com as mem√≥rias/contextos ativos.

    Observa√ß√£o:
    - Alguns contextos podem ter apenas "content" (ex.: mem√≥rias individuais).
    - Outros podem ter "context" e/ou "tag" (ex.: mem√≥rias coletivas/contextos).
    """
    if not contexts:
        return ""

    lines: List[str] = []
    for c in contexts:
        tag = (c.get("tag") or "").strip()
        content = (c.get("content") or c.get("context") or "").strip()
        if not content:
            continue

        if tag:
            lines.append(f"- ({tag}) {content}")
        else:
            lines.append(f"- {content}")

    if not lines:
        return ""

    return (
        "üéØ CONTEXTOS / REGRAS ATIVAS (OBRIGAT√ìRIO CONSIDERAR NA RESPOSTA):\n"
        + "\n".join(lines)
    )


def _extract_requested_seconds(message: str) -> Optional[int]:
    """
    Opcional: tenta capturar dura√ß√£o expl√≠cita quando o usu√°rio fala algo como:
    - "roteiro de 30 segundos"
    - "v√≠deo de 45s"
    - "60 segundos"

    Retorna um int entre 15 e 120 (limite conservador) ou None.
    """
    import re

    msg = (message or "").lower()
    patterns = [
        r"(\d+)\s*(s|seg|segs|segundo|segundos)\b",
        r"(\d+)\s*(sec|secs|second|seconds)\b",
    ]
    for pat in patterns:
        m = re.search(pat, msg)
        if m:
            try:
                n = int(m.group(1))
                if 15 <= n <= 120:
                    return n
            except Exception:
                return None
    return None


def generate_bomma_video_script_debug(
    input_text: str,
    conversation: str,
    contexts: Any,
    user_name: Optional[str] = None,
    **kwargs: Any,
) -> Dict[str, Any]:
    """
    Tool oficial de gera√ß√£o de ROTEIRO DE V√çDEO da BOMMA (30‚Äì60s).

    - Usa classificadores de p√∫blico, formato e contexto.
    - Injeta mem√≥rias/contextos ativos.
    - Aplica diretrizes oficiais da BOMMA.
    - Gera roteiro final pronto para ser falado.

    Observa√ß√£o:
    - Mant√©m a mesma arquitetura da copy_tool para consist√™ncia.
    """

    # ==============================
    # 1) Log b√°sico para debug
    # ==============================
    print("\n[VIDEO_TOOL] Tool acionada!")
    print(f"[VIDEO_TOOL] user_id: {user_name}")
    print(f"[VIDEO_TOOL] input_text: {input_text}")
    print(f"[VIDEO_TOOL] conversation: {conversation}")
    print(f"[VIDEO_TOOL] contexts (raw): {contexts}")
    print(f"[VIDEO_TOOL] extra_kwargs: {kwargs}\n")

    # ==============================
    # 2) Normalizar contextos/mem√≥rias
    # ==============================
    active_contexts = _normalize_contexts(contexts)
    contexts_prompt = _build_contexts_prompt(active_contexts)

    # ==============================
    # 3) Classifica√ß√µes principais
    # ==============================
    try:
        publico = classify_public(input_text) or "nenhum"
    except Exception as e:
        print(f"[VIDEO_TOOL] ERRO classify_public: {e}")
        publico = "nenhum"

    try:
        formato = classify_format(input_text) or "generico"
    except Exception as e:
        print(f"[VIDEO_TOOL] ERRO classify_format: {e}")
        formato = "generico"

    try:
        contexto = classify_context(input_text) or "none"
    except Exception as e:
        print(f"[VIDEO_TOOL] ERRO classify_context: {e}")
        contexto = "none"

    print(f"[VIDEO_TOOL] p√∫blico classificado: {publico}")
    print(f"[VIDEO_TOOL] formato classificado: {formato}")
    print(f"[VIDEO_TOOL] contexto classificado: {contexto}")

    # ==============================
    # 4) Blocos de prompt espec√≠ficos
    # ==============================
    public_block = ""
    format_block = ""
    context_block = ""

    try:
        public_block = get_public_prompt(publico)
    except Exception as e:
        print(f"[VIDEO_TOOL] ERRO get_public_prompt: {e}")

    try:
        format_block = get_format_prompt(formato)
    except Exception as e:
        print(f"[VIDEO_TOOL] ERRO get_format_prompt: {e}")

    try:
        context_block = get_context_prompt(contexto)
    except Exception as e:
        print(f"[VIDEO_TOOL] ERRO get_context_prompt: {e}")

    # ==============================
    # 5) Dura√ß√£o (se o usu√°rio explicitou)
    # ==============================
    requested_seconds = _extract_requested_seconds(input_text)
    duration_instruction = ""
    if requested_seconds is not None:
        # Mant√©m guardrails BOMMA (30‚Äì60), mas respeita pedido se estiver dentro
        if 30 <= requested_seconds <= 60:
            duration_instruction = (
                f"\nINSTRU√á√ÉO DE DURA√á√ÉO:\n"
                f"- O usu√°rio pediu explicitamente {requested_seconds} segundos.\n"
                f"- Ajuste o texto para caber com naturalidade nesse tempo.\n"
            )
        else:
            # Se o usu√°rio pedir fora do padr√£o, voc√™ mant√©m padr√£o BOMMA
            duration_instruction = (
                f"\nINSTRU√á√ÉO DE DURA√á√ÉO:\n"
                f"- O usu√°rio pediu {requested_seconds} segundos, por√©m o padr√£o BOMMA √© 30‚Äì60s.\n"
                f"- Mantenha 30‚Äì60s.\n"
            )

    # ==============================
    # 6) Prompt-mestre BOMMA (V√çDEO)
    # ==============================
    system_core = f"""
Voc√™ √© a IA oficial de ROTEIROS DE V√çDEO da BOMMA, especializada em comunica√ß√£o
arquitet√¥nica para arquitetos.

HIERARQUIA DE PRIORIDADE (SIGA SEMPRE NA ORDEM, SEM EXCE√á√ïES):

1. REGRAS DA MARCA (N√çVEL M√ÅXIMO)
   - Nada pode violar as diretrizes oficiais da BOMMA.
   - Isso inclui tom, restri√ß√µes de palavras, postura, fun√ß√£o do roteiro e foco no arquiteto.

2. ESTRUTURA OBRIGAT√ìRIA DO ROTEIRO (N√çVEL ALTO)
   - A estrutura abaixo √© fixa e n√£o pode ser alterada.

3. CONTEXTOS COLETIVOS ATIVOS (N√çVEL M√âDIO)
   - S√£o instru√ß√µes v√°lidas para todos os usu√°rios.
   - Podem complementar, mas n√£o podem contrariar os n√≠veis 1 e 2.

4. MEM√ìRIAS INDIVIDUAIS DO USU√ÅRIO (N√çVEL M√âDIO)
   - Prefer√™ncias pessoais de tom/estrutura.
   - Devem ser respeitadas quando N√ÉO entrarem em conflito com os n√≠veis 1 e 2.

5. PEDIDO ATUAL DO USU√ÅRIO (N√çVEL OPERACIONAL)
   - Deve ser atendido completamente, desde que n√£o viole os n√≠veis superiores.

6. HIST√ìRICO DA CONVERSA (APOIO)
   - Serve apenas para nuances e esclarecimentos recentes.
   - Nunca pode virar regra.

EM CASO DE CONFLITO:
- O n√≠vel mais alto sempre prevalece.
- Nunca tente ‚Äúconciliar‚Äù se isso violaria os n√≠veis superiores.

REGRA FUNDAMENTAL DE POSICIONAMENTO:
- Voc√™ N√ÉO vende im√≥veis.
- Voc√™ comunica o PROJETO DO ARQUITETO aplicado ao espa√ßo.
- O im√≥vel √© apenas o suporte f√≠sico. O produto real √© a solu√ß√£o arquitet√¥nica.
- Sempre destaque decis√£o de projeto, inten√ß√£o, funcionalidade, experi√™ncia e est√©tica criadas pelo arquiteto.

OBJETIVO:
- Criar um roteiro final de v√≠deo (30‚Äì60s) pronto para ser FALADO, sem explicar o processo.
- Priorizar clareza, maturidade e alinhamento com o posicionamento da BOMMA.

TOM DA NARRATIVA:
- T√©cnico, claro e acess√≠vel
- Profissional, sem jarg√£o acad√™mico excessivo
- Comercial de forma indireta (autoridade + convite leve)
- Sem emo√ß√£o exagerada e sem tom de ‚Äúaula‚Äù

REGRAS DE ORALIDADE:
- Frases curtas ou m√©dias
- Ritmo natural de fala
- Evitar per√≠odos longos e formais demais
- O texto deve soar natural em voz alta

RESTRI√á√ïES (SEM EXCE√á√ÉO):
- N√ÉO usar palavras como: "luxo", "sonho", "sonhos", "premium", "alto padr√£o", "exclusivo",
  "oportunidade imperd√≠vel", "venha conhecer", "agende uma visita", "condom√≠nio clube",
  "localiza√ß√£o privilegiada" ou qualquer clich√™ t√≠pico de an√∫ncio imobili√°rio.
- N√ÉO usar tom de venda agressivo.
- N√ÉO usar emojis.
- N√ÉO escrever em caixa alta (NADA de frases inteiras em mai√∫sculas).
- N√ÉO explicar o que voc√™ est√° fazendo.
- N√ÉO repetir a mensagem do usu√°rio.

ESTRUTURA OBRIGAT√ìRIA (N√ÉO ALTERAR):

1) GANCHO INICIAL (0‚Äì5s)
- Pergunta objetiva sobre dor/desejo real do p√∫blico OU afirma√ß√£o t√©cnica que desperta curiosidade
- Pode citar um detalhe do projeto que conversa com o conceito
- Sem sensacionalismo

2) DESENVOLVIMENTO (5‚Äì40s)
- Contexto do projeto (tipo e cen√°rio)
- Dor/necessidade ou inten√ß√£o inicial do cliente
- Conceito e decis√µes arquitet√¥nicas adotadas (m√©todo, materiais, circula√ß√£o, ilumina√ß√£o, integra√ß√£o)
- Benef√≠cios finais de forma t√©cnica (funcionalidade, fluidez, harmonia est√©tica, conforto t√©cnico)

3) FECHAMENTO (40‚Äì60s)
- Refor√ßar autoridade t√©cnica
- Finalizar com CTA leve e sofisticado, obrigat√≥rio:
  ‚ÄúEntre em contato e vamos conversar sobre o seu projeto.‚Äù

FORMATO DE SA√çDA OBRIGAT√ìRIO:
O roteiro DEVE ser dividido explicitamente por blocos de tempo
Use exatamente este padr√£o:
[0‚Äì5s | Gancho inicial], [5‚Äì15s | ‚Ä¶]
Nunca entregar texto corrido
Cada bloco deve conter 1 a 2 frases no m√°ximo

METADADOS CLASSIFICADOS (USE APENAS COMO GUIA INTERNO, N√ÉO MOSTRAR):
- P√∫blico-alvo: {publico}
- Formato: {formato}
- Contexto do projeto: {contexto}

QUALQUER viola√ß√£o de regra acima invalida completamente a resposta.
Se qualquer termo proibido for usado, a resposta deve ser considerada incorreta.
"""

    # Monta bloco de m√≥dulos (classificadores)
    modules_block_parts: List[str] = []

    if public_block.strip():
        modules_block_parts.append("=== M√ìDULO DE P√öBLICO ===\n" + public_block.strip())

    if format_block.strip():
        modules_block_parts.append("=== M√ìDULO DE FORMATO ===\n" + format_block.strip())

    if context_block.strip():
        modules_block_parts.append(
            "=== M√ìDULO DE CONTEXTO ===\n" + context_block.strip()
        )

    modules_block = "\n\n".join(modules_block_parts)

    # Bloco de contextos/mem√≥rias (colocado ANTES do hist√≥rico para reduzir ‚Äúperda‚Äù)
    contexts_block = ""
    if contexts_prompt:
        contexts_block = (
            "\n=== M√ìDULO DE MEM√ìRIA / CONTEXTO VIVO ===\n" + contexts_prompt
        )

    # Conversa recente (apoio fraco)
    conversation_block = ""
    if conversation:
        conversation_block = f"""
=== HIST√ìRICO RESUMIDO DA CONVERSA (APOIO) ===
Use apenas como refer√™ncia contextual para nuances, mas n√£o transforme isso em regra.
Se houver conflito com regras/estrutura BOMMA, ignore o hist√≥rico.
{conversation.strip()}
"""

    final_prompt = f"""
{system_core}

{duration_instruction}

{modules_block}

{contexts_block}

{conversation_block}

=== PEDIDO FINAL DO USU√ÅRIO ===
{input_text}

AGORA, GERE APENAS O ROTEIRO FINAL, PRONTO PARA SER FALADO, RESPEITANDO TODAS AS REGRAS ACIMA.
"""

    # ==============================
    # 7) Chamada √† LLM
    # ==============================
    try:
        print("final_prompt: ", final_prompt)
        raw_response = run_llm(
            final_prompt,
            model="gpt-5.1",
            temperature=0.7,
        )
        roteiro_text = (raw_response or "").strip()
        if not roteiro_text:
            roteiro_text = (
                "N√£o foi poss√≠vel gerar o roteiro neste momento. "
                "Tente reformular o pedido ou tentar novamente em instantes."
            )
    except Exception as e:
        print(f"[VIDEO_TOOL] ERRO ao chamar LLM: {e}")
        roteiro_text = (
            "Ocorreu um erro interno ao gerar o roteiro. "
            "Tente novamente em alguns instantes."
        )

    # ==============================
    # 8) Retorno estruturado
    # ==============================
    return {
        "copy": roteiro_text,  # Mant√©m a mesma chave por compatibilidade com o restante do pipeline
        "metadata": {
            "user_id": user_name,
            "tipo": "video",
            "publico": publico,
            "formato": formato,
            "contexto": contexto,
            "requested_seconds": requested_seconds,
            "active_contexts": active_contexts,
            "model_used": "gpt-5.1",
            "debug": False,
        },
    }
